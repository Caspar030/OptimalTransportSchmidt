{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from scipy.integrate import quad, nquad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 1\n",
    "\n",
    "input_dim = dim\n",
    "hidden_dim = 4 * input_dim\n",
    "output_dim = 1\n",
    "\n",
    "activation_func = \"relu\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = 1.0  # Tbc\n",
    "rho = 1.0  # Tbc\n",
    "\n",
    "def f(x):\n",
    "    return 1\n",
    "\n",
    "def h_i(x, i):\n",
    "    return x ** 2  # Tbc\n",
    "\n",
    "def g(x):\n",
    "    return x ** 2  # tbc\n",
    "\n",
    "def mu_i_density(x, i):\n",
    "    return np.exp(-x**2 / 2) / np.sqrt(2 * np.pi)  # tbc\n",
    "\n",
    "def sample_mu(n_samples, dim):\n",
    "    return tf.random.normal((n_samples, dim))  # tbc\n",
    "\n",
    "def beta_gamma():\n",
    "    return 1\n",
    "\n",
    "def cost_function(x, y):\n",
    "    return x+y\n",
    "\n",
    "def theta(x, y):\n",
    "    return 1\n",
    "\n",
    "def phi_theta_gamma(samples):\n",
    "    h_integral = tf.reduce_sum(tf.map_fn(lambda i: tf.reduce_mean(h_i(samples[:, i], i)), tf.range(dim), dtype=tf.float32))\n",
    "    g_integral = tf.reduce_mean(tf.map_fn(g, samples, dtype=tf.float32))\n",
    "\n",
    "    # y_values = tf.random.normal((10 ** 4, dim))  # TODO: Not explicit n_samples\n",
    "    # theta_integral = tf.constant(0.0, dtype=tf.float32)\n",
    "    # for x in samples:\n",
    "    #     for y in y_values:\n",
    "    #         integral_value += beta_gamma(f(y) - tf.reduce_sum([h_i(y, i) for i in tf.range(dim)]) - lam * cost_function(x, y) - g(x)) * theta(x, y)\n",
    "\n",
    "    theta_integral = 0\n",
    "\n",
    "    return lam * rho + h_integral + g_integral + theta_integral\n",
    "\n",
    "class CustomLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def call(self, x_true, x_pred):\n",
    "        #samples = sample_mu(tf.shape(x_pred)[0], dim)\n",
    "        return phi_theta_gamma(x_pred)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initilizer = RandomNormal(mean=0.0, stddev=1.0)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(input_dim,)))\n",
    "model.add(Dense(units=hidden_dim, activation=activation_func, kernel_initializer=initilizer))\n",
    "model.add(Dense(units=hidden_dim, activation=activation_func, kernel_initializer=initilizer))\n",
    "model.add(Dense(units=hidden_dim, activation=activation_func, kernel_initializer=initilizer))\n",
    "model.add(Dense(units=output_dim, kernel_initializer=initilizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.01,\n",
    "    decay_steps=10000, decay_rate=0.9\n",
    ")\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(optimizer=opt, loss=CustomLoss())\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10 ** 4\n",
    "x_samples = sample_mu(n_samples, dim).numpy()\n",
    "x_true_irrelevant = np.zeros_like(x_samples)\n",
    "\n",
    "model.fit(x_samples, x_true_irrelevant, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = tf.linspace(-10, 10, 500)\n",
    "x_test = tf.reshape(x_test, (-1, 1))\n",
    "y_test = model.predict(x_test)\n",
    "\n",
    "print(x_test, y_test)\n",
    "\n",
    "plt.plot(x_test, y_test, label='Approximierte Funktion')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.integrate import quad, nquad\n",
    "\n",
    "# Beispiel für \\rho\n",
    "rho = 1.0  # Anpassen je nach Definition\n",
    "lambda_val = 1.0\n",
    "\n",
    "#Dummy-Beispiel für h_i und g. Muss später per NN optimiert werden (?).\n",
    "def h_i(x, i):\n",
    "    return x**2\n",
    "\n",
    "def g(x):\n",
    "    return sum(x)\n",
    "\n",
    "# Beispiel für \\beta_{\\gamma} Funktion\n",
    "def beta_gamma(z, gamma):\n",
    "    # Dummy-Beispiel für die Funktion, anpassen je nach Definition\n",
    "    return np.exp(-gamma * z**2)\n",
    "\n",
    "# Dummy-Funktion für Verteilungen \\bar{\\mu}_i und \\bar{\\mu}\n",
    "def mu_i_density(y, i):\n",
    "    # Dummy-Dichtefunktion, anpassen je nach Definition\n",
    "    return np.exp(-y**2 / 2) / np.sqrt(2 * np.pi)\n",
    "\n",
    "def mu_density(x):\n",
    "    # Dummy-Dichtefunktion, anpassen je nach Definition\n",
    "    return np.exp(-np.sum(x**2) / 2) / (2 * np.pi)**(len(x)/2)\n",
    "\n",
    "# Kostenfunktion c(x, y)\n",
    "def cost_function(x, y):\n",
    "    # Beispiel-Kostenfunktion, anpassen je nach Definition\n",
    "    return np.linalg.norm(x - y)\n",
    "\n",
    "# Funktion \\phi_{\\theta,\\gamma}(f)\n",
    "def phi_theta_gamma(f, theta, gamma, d):\n",
    "\n",
    "    # Integrale berechnen\n",
    "    h_integral = sum(quad(lambda y: h_i(y, i) * mu_i_density(y, i), -np.inf, np.inf)[0] for i in range(d))\n",
    "    g_integral = nquad(lambda *x: g(x) * mu_density(np.array(x)), [(-np.inf, np.inf)] * d)[0]\n",
    "\n",
    "    def integrand(x, y):\n",
    "            return beta_gamma(f(y) - sum(h_i(y[0], i) for i in range(d)) - lambda_val * cost_function(x, y) - g, gamma) * theta(x, y)\n",
    "\n",
    "    beta_integral = nquad(integrand, [(-np.inf, np.inf)] * (2*d))\n",
    "\n",
    "    return lambda_val * rho + h_integral + g_integral + beta_integral\n",
    "\n",
    "\n",
    "    # # Initiale Parameter\n",
    "    # initial_params = np.zeros(d + 1 + d)\n",
    "    \n",
    "    # # Optimierung\n",
    "    # result = minimize(objective, initial_params, method='SLSQP')\n",
    "    \n",
    "    # return result.fun\n",
    "\n",
    "\n",
    "# Beispielaufruf der Funktion\n",
    "if __name__ == \"__main__\":\n",
    "    # Dummy \\theta Funktion\n",
    "    def theta(x, y):\n",
    "        return 1.0  # Dummy-Wert, anpassen je nach Definition\n",
    "\n",
    "    # Dummy f Funktion\n",
    "    def f(y):\n",
    "        return np.sum(y**2)  # Dummy-Wert, anpassen je nach Definition\n",
    "\n",
    "    # Parameter\n",
    "    gamma = 1.0\n",
    "    d = 1  # Dimension\n",
    "\n",
    "    # Funktionsaufruf\n",
    "    result = phi_theta_gamma(f, theta, gamma, d)\n",
    "    print(f'Result: {result}')\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Beispiel-Optimierungsproblem: Minimierung von (x - 2)^2\n",
    "# Ziel ist es, eine Funktion f(x) zu approximieren, die dieses Problem minimiert.\n",
    "\n",
    "# Erstellen Sie einige Beispiel-Daten (unüberwachtes Lernen)\n",
    "x_train = np.random.rand(1000, 1) * 4 - 2  # Werte zwischen -2 und 2\n",
    "\n",
    "# Definieren Sie die Struktur des neuronalen Netzes\n",
    "model2 = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(1,)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Definieren Sie die benutzerdefinierte Verlustfunktion\n",
    "def custom_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean((y_pred - 2) ** 2)  # Beispiel: (f(x) - 2)^2\n",
    "\n",
    "# Kompilieren Sie das Modell mit der benutzerdefinierten Verlustfunktion\n",
    "model2.compile(optimizer=Adam(learning_rate=0.01), loss=custom_loss)\n",
    "\n",
    "# Da es sich um unüberwachtes Lernen handelt, können wir Dummy-Zielwerte verwenden (werden nicht wirklich verwendet)\n",
    "y_dummy = np.zeros_like(x_train)\n",
    "\n",
    "# Trainieren Sie das Modell\n",
    "model2.fit(x_train, y_dummy, epochs=50, batch_size=32)\n",
    "\n",
    "# Testen Sie das Modell\n",
    "x_test = np.linspace(-2, 2, 100).reshape(-1, 1)\n",
    "y_pred = model2.predict(x_test)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(x_test, y_pred, label='Approximierte Funktion')\n",
    "plt.axhline(2, color='r', linestyle='--', label='Zielwert 2')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLstoch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
